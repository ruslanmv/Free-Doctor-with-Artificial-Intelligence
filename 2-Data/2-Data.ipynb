{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d086c9ff-22b8-4e97-8572-808c48096136",
   "metadata": {},
   "source": [
    "# Data Creation for Free Doctor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4b91a-2cdb-4361-b1a8-5f4e6cd1ce6d",
   "metadata": {},
   "source": [
    "In this section we are going to create the dataset, we are going to download the raw data and clean and create a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac32e1-c7bc-4897-a51e-5724c4b31425",
   "metadata": {},
   "source": [
    "First, let us download the online datasets to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203aa753-7fb3-4598-ab99-576e4ac471ca",
   "metadata": {},
   "source": [
    "The MedDialog dataset (English) contains conversations (in English) between doctors and patients. It has 0.26 million dialogues. The data is continuously growing and more dialogues will be added. The raw dialogues are from healthcaremagic.com and icliniq.com. All copyrights of the data belong to healthcaremagic.com and icliniq.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05371826-f8bc-45c5-88db-ebd87c7a84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8610028a-9fe1-4ec1-a1e7-5bb40533ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bd7bd0-1974-43e9-baa3-e2e55cb9c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://drive.google.com/drive/folders/1-5mQW2gNj_kcBobllL9EpbJcUcT5aFpE?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0b364b-eb38-4e45-ba4e-6ec21708c857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\rusla\\\\Dropbox\\\\23-GITHUB\\\\Projects\\\\Free-Doctor-with-Artificial-Intelligence\\\\2-Data\\\\Medical-Dialogue-System\\\\dialogue_0.txt',\n",
       " 'C:\\\\Users\\\\rusla\\\\Dropbox\\\\23-GITHUB\\\\Projects\\\\Free-Doctor-with-Artificial-Intelligence\\\\2-Data\\\\Medical-Dialogue-System\\\\dialogue_1.txt',\n",
       " 'C:\\\\Users\\\\rusla\\\\Dropbox\\\\23-GITHUB\\\\Projects\\\\Free-Doctor-with-Artificial-Intelligence\\\\2-Data\\\\Medical-Dialogue-System\\\\dialogue_2.txt',\n",
       " 'C:\\\\Users\\\\rusla\\\\Dropbox\\\\23-GITHUB\\\\Projects\\\\Free-Doctor-with-Artificial-Intelligence\\\\2-Data\\\\Medical-Dialogue-System\\\\dialogue_3.txt',\n",
       " 'C:\\\\Users\\\\rusla\\\\Dropbox\\\\23-GITHUB\\\\Projects\\\\Free-Doctor-with-Artificial-Intelligence\\\\2-Data\\\\Medical-Dialogue-System\\\\dialogue_4.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdown.download_folder(url, quiet=True, use_cookies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ef2a2-9398-470d-a85f-86df74f7ceaf",
   "metadata": {},
   "source": [
    "There are 5 raw dialogs that we are going to process to create the dataset to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcea4e3-2b6c-4d92-97d6-9c0b4fad5388",
   "metadata": {},
   "source": [
    "We are going to create a Dataset with the following schema:\n",
    "\n",
    "- qid\t - Int\n",
    "- question - String\t\n",
    "- relevant - String\t\n",
    "- answers -Int\n",
    "\n",
    "The conversion of text to json.\n",
    "Then we will create the pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baaef232-7a75-454c-bf55-b8d4bdbef1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing  modules\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d2678a8-dd10-4489-a0a6-684c5ddc2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tools import timer\n",
    "t = timer.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7b90d5-0372-4e73-96ee-ed53bc02f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_content(filename):\n",
    "    '''\n",
    "    filename:  The filename must be txt format and stored in the \n",
    "               ./2-Data/Medical-Dialogue-System/ folder\n",
    "    res: The output is the list of all dialogues separated in each file.\n",
    "    '''\n",
    "    #to get the current working directory\n",
    "    path = os.getcwd()\n",
    "    file = os.path.join(path, \"Medical-Dialogue-System\", filename)\n",
    "    subdirectory=filename.replace(\".txt\",\"\")\n",
    "    #creating a new directory called data\n",
    "    out_dir=os.path.join(path, \"data\",subdirectory)\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    out_n = 0\n",
    "    done = False\n",
    "    try:   \n",
    "        with open(file, encoding=\"utf-8\") as in_file:\n",
    "            while not done: #loop over output file names\n",
    "                # Join various path components\n",
    "                name=f\"out{out_n}.txt\"\n",
    "                file_tmp=os.path.join(path, \"data\", subdirectory, name)\n",
    "                #print(file_tmp)\n",
    "                with open(file_tmp, \"w\", encoding=\"utf-8\") as out_file: #generate an output file name\n",
    "                    while not done: #loop over lines in the input file and write to the output file\n",
    "                        try:\n",
    "                            line = next(in_file).strip() #strip whitespace for consistency\n",
    "                        except StopIteration:\n",
    "                            done = True\n",
    "                            break\n",
    "                        if \"id=\" in line: #more robust than 'if line == \"SPLIT\\n\":'\n",
    "                            break\n",
    "                        else:\n",
    "                            out_file.write(line + '\\n') #must add back in newline because we stripped it out earlier \n",
    "                    out_n += 1 #increment output file name integer\n",
    "     \n",
    "    except Exception as error:\n",
    "        print(\"An error occurred to open dialog:\", error) # An error occurred: name 'x' is not defined\n",
    "    from os import walk\n",
    "    # folder path\n",
    "    dir_path = out_dir\n",
    "    # List to store files name\n",
    "    res = []\n",
    "    for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "        res.extend(file_names)\n",
    "    #print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13e8e5d-769c-4281-813d-1d6e62d6f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findword(str, word):\n",
    "    m = re.search(word, str)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd0de51-8ea1-45e9-a004-0f823a86e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(text_as_string,name_partial):\n",
    "    string = re.sub('http://\\S+|https://\\S+', '', text_as_string)\n",
    "    keywords = {'Description', 'Dialogue', 'Patient:', 'Doctor:'}\n",
    "    text=re.split(r'\\n(?=Description|Dialogue|Patient|Doctor)' , string)\n",
    "    updated_dic ={}\n",
    "    for str in  text:    \n",
    "        for word in keywords:\n",
    "            #print(\"Looking for {}\".format(word))\n",
    "            res = findword(str,word)\n",
    "            if res is None:\n",
    "                log=\"Word not found!!\"\n",
    "                #print(log)\n",
    "            else:\n",
    "                #print(\"Search Success!!\")\n",
    "                # Python program to convert text\n",
    "                # file to JSON\n",
    "                # The file to be converted to\n",
    "                # json format\n",
    "                lines = str\n",
    "                # dictionary where the lines from\n",
    "                # text will be stored\n",
    "                parsed_dict = {}\n",
    "                # reads each line and trims of extra the spaces\n",
    "                # and gives only the valid words\n",
    "                #print(\"Analyzing text:\",lines)\n",
    "                try:\n",
    "                    command, content = lines.strip().split(None, 1) \t \t\n",
    "                    command=command.replace(\":\",\"\") \n",
    "                    content=content.strip()\n",
    "                    content=content.replace(\"\\n\", \" \")\n",
    "                    parsed_dict[command] = content\n",
    "                    updated_dic.update(parsed_dict)\n",
    "                    \n",
    "                except:\n",
    "                  #print(\"No recurrence found\")\n",
    "                    pass\n",
    "    #print(\"The output dataframe is:\")\n",
    "    df = pd.DataFrame(updated_dic, index = [name_partial])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a95d607-d1e7-4e4e-91a6-ec6fc45d4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(filename):\n",
    "    '''\n",
    "    filename:  The filename must be txt format and stored in the \n",
    "               ./2-Data/Medical-Dialogue-System/ folder\n",
    "    df: The output is a dataframe\n",
    "    '''\n",
    "    #to get the current working directory\n",
    "    path = os.getcwd()\n",
    "    res=split_content(filename)\n",
    "    # create an Empty DataFrame object\n",
    "    df = pd.DataFrame()\n",
    "    for partial in res:\n",
    "        name_partial=partial\n",
    "        subdirectory=filename.replace(\".txt\",\"\")\n",
    "        file_partial=os.path.join(path, \"data\", subdirectory,name_partial)\n",
    "        text_as_string = open(file_partial, encoding=\"utf-8\").read()\n",
    "        #print(partial)\n",
    "        df_partial=create_dataframe(text_as_string,name_partial)\n",
    "        # A continuous index value will be maintained\n",
    "        # across the rows in the new appended data frame.\n",
    "        frames = [df, df_partial]\n",
    "        df = pd.concat(frames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2beb7bea-abfa-4f4f-a4ff-bfe056d5c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(filename):\n",
    "    print(\"Creating dataframe ...\")\n",
    "    dfa=create(filename)\n",
    "    dfa=dfa.reset_index(names=\"Filename\")\n",
    "    file_name=filename.replace(\".txt\",\".csv\")\n",
    "    path = os.getcwd()\n",
    "    out_dir=os.path.join(path, \"data\", \"csv\")\n",
    "    out_file=os.path.join(out_dir,file_name)\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    dfa.to_csv(out_file, sep='\\t', encoding='utf-8', index=False)\n",
    "    df = pd.read_csv(out_file, sep = '\\t')\n",
    "    print(\"File created: \",out_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28194608-e120-46d3-88ac-69d7b00a22aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataframe ...\n",
      "File created:  C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\Free-Doctor-with-Artificial-Intelligence\\2-Data\\data\\csv\\test.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Description</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out0.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>out1.txt</td>\n",
       "      <td>Q. What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi doctor,I am just wondering what is abutting...</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out2.txt</td>\n",
       "      <td>Q. Every time I eat spicy food, I poop blood. ...</td>\n",
       "      <td>Hi doctor, I am a 26 year old male. I am 5 fee...</td>\n",
       "      <td>Hello. I have gone through your information an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>out3.txt</td>\n",
       "      <td>Q. Will Nano-Leo give permanent solution for e...</td>\n",
       "      <td>Hello doctor, I am 48 years old. I am experien...</td>\n",
       "      <td>Hi. For further doubts consult a sexologist on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename                                        Description  \\\n",
       "0  out0.txt                                                NaN   \n",
       "1  out1.txt      Q. What does abutment of the nerve root mean?   \n",
       "2  out2.txt  Q. Every time I eat spicy food, I poop blood. ...   \n",
       "3  out3.txt  Q. Will Nano-Leo give permanent solution for e...   \n",
       "\n",
       "                                             Patient  \\\n",
       "0                                                NaN   \n",
       "1  Hi doctor,I am just wondering what is abutting...   \n",
       "2  Hi doctor, I am a 26 year old male. I am 5 fee...   \n",
       "3  Hello doctor, I am 48 years old. I am experien...   \n",
       "\n",
       "                                              Doctor  \n",
       "0                                                NaN  \n",
       "1  Hi. I have gone through your query with dilige...  \n",
       "2  Hello. I have gone through your information an...  \n",
       "3  Hi. For further doubts consult a sexologist on...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"test.txt\"\n",
    "#filename=\"dialogue_0.txt\"\n",
    "create_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46a13d-2128-439b-bcfa-57d2df2307b2",
   "metadata": {},
   "source": [
    "We select the list of documents to create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c39f514-ca47-4878-8e8d-a2c3e02f7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=[\"dialogue_0.txt\",\n",
    "           \"dialogue_1.txt\",\n",
    "           \"dialogue_2.txt\",\n",
    "           \"dialogue_3.txt\",\n",
    "           \"dialogue_4.txt\"]\n",
    "#filenames=[filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9621e-e44d-4bab-a213-067db63fa55e",
   "metadata": {},
   "source": [
    "We perform the creation of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4d71845-4f53-47e2-8e66-c8a36165cf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataframe ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [03:48<15:13, 228.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created:  C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\Free-Doctor-with-Artificial-Intelligence\\2-Data\\data\\csv\\dialogue_0.csv\n",
      "Done\n",
      "Creating dataframe ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [08:57<13:47, 275.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created:  C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\Free-Doctor-with-Artificial-Intelligence\\2-Data\\data\\csv\\dialogue_1.csv\n",
      "Done\n",
      "Creating dataframe ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [36:57<30:33, 916.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created:  C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\Free-Doctor-with-Artificial-Intelligence\\2-Data\\data\\csv\\dialogue_2.csv\n",
      "Done\n",
      "Creating dataframe ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [1:00:39<18:36, 1116.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created:  C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\Free-Doctor-with-Artificial-Intelligence\\2-Data\\data\\csv\\dialogue_3.csv\n",
      "Done\n",
      "Creating dataframe ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:04:45<00:00, 777.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created:  C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\Free-Doctor-with-Artificial-Intelligence\\2-Data\\data\\csv\\dialogue_4.csv\n",
      "Done\n",
      "Elapsed time: 3885.3336 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t.start()\n",
    "for filename in tqdm(filenames):\n",
    "    create_csv(filename)\n",
    "    print(\"Done\")\n",
    "t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19f544fa-fb18-42ec-a4e3-22334967f6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb3bcb-5054-48dc-bdad-049a4d3152dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b39f3b-65b8-4a90-bb6c-aa856944dba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c40117-5106-42cd-b591-c865f35692e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (GPT)",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
